input
## 读取文件
file {
          path => "/home/logs/*.log"
          start_position => "beginning"
          codec => plain {
          charset => "GBK" }
          type => "file"
}

## Syslog接收
syslog {
          type => "syslog"
          port => 514
          codec => plain {
          charset => "UTF-8" }
}

## 自动生成日志
generator {
          type => "test"
          message => "118.137.224.185 - - [14/Jul/2014:15:27:45 +0800] GET /usercenter/login_datason.jsp?callback=jQuery18305208275022450835_1405322856752&_=1405322858111 HTTP/1.1 200 71 http://www.zooboa.com/; Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Maxthon/3.0 Chrome/22.0.1229.79 Safari/537.1 0.006 0.006 ."
          count => 100000000000000000000
}

## Tcp接收
示例1:
tcp {
          type => "monitor"
          port => 514
          codec => json { charset => "UTF-8" }
}

## Udp接收
示例1:
udp {
          type => "netflow"
          port => 2055
          codec => netflow
}
示例2:
udp {
          type => "syslog"
          port => 514
          codec => plain { charset => "GBK" }
          workers => 2
}
示例3：（接收时进行编码和多行处理）
udp {
          type => "udp"
          codec => multiline {
                    pattern => "^%{TIMESTAMP_ISO8601} %{LOGLEVEL}"
                    negate => true
                    charset => "GBK"
                    what => "previous"
          }
          # workers => 8
          port => 514
}

## SNMPTrap接收
snmptrap  {
          community => "snmp"
          type => "snmptrap"
          port => 1062
}

## Redis接收
redis {
          host => "10.0.0.178"
          port => 6379
          data_type => "list"
          key => "biglog"
}

##ZeroMP接收
zeromq {
          address => ["tcp://192.168.8.145:8889"]
          mode => "client"
          type => "zmq-input"
          topic => "weblog"
          topology => "pubsub"
          codec => "json"
}

##kafka接收
kafka {
          topic_id => "51idc"
          type => "netflow"
          codec => "plain"
          consumer_threads => 48
          fetch_message_max_bytes => 5242880
          queue_size => 200
}

## Logstash-Forwarder接收配置
lumberjack {
          port => 6782
          ssl_certificate => "/etc/logstash/server.crt"
          ssl_key => "/etc/logstash/server.key"
          type => "forwarder"
}
filter
##clone字段
clone {
          clones => ["msg_clone"]
          add_tag => "error"
}

#drop丢掉
drop{}

##grok切割（需要补充常见切割的规则）
grok {
     type => "syslog"
     patterns_dir => "./patterns"
     match => [ "message","%{WEB}" ]
     add_tag => "web"
}

## exec执行命令
exec {
          command => "curl -s localhost:8161/admin/xml/queues.jsp"
          interval => 10
          type => 'amq'
}

## 安全检测模块
示例1：（注意是useragent还是agent）
grok {
          tags => "nginx"
          match => ["request","(\w+)'|(\w+)%20and%20(\S+)|(\w+)%20or%20(\S+)|select%20|insert%20|%20from%20|%20where%20|union%20|DECLARE%20@S%20CHAR|%20AS%20CHAR"]
          add_tag => "SQL Injection Attack"
     }
grok {
          tags => "nginx"
          match => ["request","(\S)%3C(\S+)%3E|(\S)%3C(\S+)%2F%3E|(\S+)<(\S+)>|(\S+)<(\S+)\/>|onerror|onmouse|expression|\"|alert|document\.|prompt\("]
          add_tag => "XSS Attack"
}
grok {
          tags => "nginx"
          match => ["request","/etc/passwd|\/%c0%ae%c0%ae|\/%2E%2E|boot\.ini|win\.ini|\.\.\/|access\.log|httpd\.conf|nginx\.conf|/proc/self/environ"]
          add_tag => "File Include Attack"
}
grok {
          tags => "nginx"
          match => ["request","denyMethodExecution|allowStaticMethodAccess"]
          add_tag => "Strus2 Attack"
}
grok {
          tags => "nginx"
          match => ["request","\/cmd\.asp|\/diy\.asp|\.asp;|\/(\w+)\.(\w+)\/(\w+)\.php|\.php\.|eval\(|%eval|\.jsp?action=|fsaction=",status,"200"]
          add_tag => "BackDoor Attack"
}
grok {
          tags => "nginx"
          match => ["useragent","HTTrack|harvest|audit|dirbuster|pangolin|nmap|sqln|-scan|hydra|Parser|libwww|BBBike|sqlmap|w3af|owasp|Nikto|fimap|havij|PycURL|zmeu|BabyKrokodil|netsparker|httperf|bench"]
          add_tag => "WebScan Attack"
}
示例2：
if [request] =~ /(\w+)'|(\w+)%20and%20(\S+)|(\w+)%20or%20(\S+)|select%20|insert%20|%20from%20|%20where%20|union%20|DECLARE%20@S%20CHAR|%20AS%20CHAR/ {
          mutate {add_tag => "SQL Injection Attack"}
} else if [request] =~ /(\S)%3C(\S+)%3E|(\S)%3C(\S+)%2F%3E|(\S+)<(\S+)>|(\S+)<(\S+)\/>|onerror|onmouse|expression|\"|alert|document\.|prompt\(/ {
          mutate {add_tag => "XSS Attack"}
} else if [request] =~ /\/etc\/passwd|\/%c0%ae%c0%ae|\/%2E%2E|boot\.ini|win\.ini|\.\.\/|access\.log|httpd\.conf|nginx\.conf|\/proc\/self\/environ/ {
          mutate {add_tag => "File Include Attack"}
} else if [request] =~ /denyMethodExecution|allowStaticMethodAccess/ {
          mutate {add_tag => "Strus2 Attack"}
} else if [request] =~ /\/cmd\.asp|\/diy\.asp|\.asp;|\/(\w+)\.(\w+)\/(\w+)\.php|\.php\.|eval\(|%eval|\.jsp?action=|fsaction=",response,"200"/ {
          mutate {add_tag => "BackDoor Attack"}
} else if [agent] =~ "HTTrack|harvest|audit|dirbuster|pangolin|nmap|sqln|-scan|hydra|Parser|libwww|BBBike|sqlmap|w3af|owasp|Nikto|fimap|havij|PycURL|zmeu|BabyKrokodil|netsparker|httperf|bench" {
          mutate {add_tag => "WebScan Attack"}
}

##翻译 （针对类似netflow.protocol 也用 [netflow][protocol]）
示例1：（城市翻译）
translate {
          field => "[geoip][real_region_name]"
          destination => "province"
          dictionary_path => "/home/translate/province"
          refresh_interval => 86400
}
translate {
          field => "[geoip][city_name]"
          destination => "city"
          dictionary_path => "/home/translate/city"
          refresh_interval => 86400
}
示例2：
translate {
          tags => "nginx"
          field => "appname"
          destination => "appname2"
          dictionary => [ "17", "UDP",
                    "6", "TCP",
                    "112", "VRRP" ]
          dictionary_path => "/home/translate/appname"
          add_field => { "sfully" => "%{customer} %{appname}" }
}

## 日期匹配设置
date {
          tags => "nginx"
          match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]
          add_tag => [ "dated" ]
}

## GeoIP设置
示例1：（新版）
geoip {
     source => "clientip"
}
示例2：
geoip {
          tags => "nginx"
          source => "clientip"
          add_tag => [ "geoip" ]
          database => "/home/logstash/vendor/geoip/GeoLiteCity.dat"
}
geoip {
          tags => "nginx"
          source => "clientip"
          database => "/home/logstash/vendor/geoip/GeoIPASNum.dat"
}

## KeyValue配置
示例1：
kv {
          type =>  "nginx"
          source => "request"
          field_split => "&?"
          value_split => "="
}
示例2：
kv {
          source => "details"
          include_keys => [ "retcode", "errno", "Disconnect from cmd", "tid", "respond", "path", "transid" ]
          field_split => ","
          value_split => ":"
          trimkey => "<>\[\],"
}

## URL解码配置
urldecode {
          type => "nginx"
          all_fields => true
          #field => [ "request", "referrer" ]
}

## UserAgent解码配置
useragent {
          source => "agent"
          target => "ua"
}

## mutate字段更改配置
示例1：
mutate {
          convert => [ "[geoip][coordinates]", "float" ]
          convert => [ "bodybytes", "integer" ]
          replace => [ "message", "%{timestamp} %{description}" ]
          update => [ "domain", "bestdomain" ]
          rename => [ "domain", "newdomain" ]
          gsub => [ "domain", "d.colafile.com", "newdomain" ]
          add_field => { "fullurl" => "%{domain}%{request}" }
}
示例2：多行合并一行（即：\n 换成 “空”）
mutate {
          gsub => ["message", "\n", ""]
}
示例3：删除某些字段
mutate {
          remove => [ "@source", "@message", "@version", "message", "host",  "IP_protocol" ]
}
示例4：转换数据类型（支持：integer, float, string）
mutate {
          convert => [ "[netflow][in_bytes2]", "integer" ]
}

## 数据统计配置
metrics {
          type => "syslog"
          #meter => "http.%{status}"
          meter => "events"
          add_tag => "metric"
          add_field => { "newmessage" => "rate: %{events.rate_1m},that in %{events.count}" }
          rates => [1]
}

## DNS解析配置
dns {
          type => "syslog"
          reverse => [ "clientip" ]
          resolve => [ "www.xx.com" ]
          action => "append"
          nameserver => "8.8.8.8"
          add_tag => "dnsed"
}

##xml格式处理
示例1：
xml {
#              store_xml => "false"
               source => message
               target => "doc"
               add_tag => "xml"
#                xpath => [
#                       "/Response/Result/*/@DevSerial","DevSerial",
#                       "/Response/Result/*/@OperationCode","OperationCode",
#                       "/Response/Result/*/@Algorithm","Algorithm",
#                       "/Response/Result/*/@Key","Key"
#               ]
}
示例2：
xml {
          source => info
          target => "doc"
          add_tag => "xml"
}

##multiline多行日志处理
multiline {
          type => "file"
          pattern => "^%{YEAR}[/-]%{MONTHNUM}[/-]%{MONTHDAY}"
          negate => true
          what => "previous"
}

##elapsed：统计一系列操作花费时间
if "Begin to execute the EMP Business flow" in [info] {
        grok {
               match => ["info","Begin to execute the EMP Business flow \[%{WORD:operation}\]"]
                add_tag => ["Started"]
        }
} else if "Execute the EMP Business flow" in [info] and "end" in [info]{
        grok {
               match => ["info","Execute the EMP Business flow \[%{WORD:operation}\]"]
                add_tag => ["Ended"]
        }
}
elapsed {
        start_tag => "Started"
        end_tag => "Ended"
        unique_id_field => "operation"
}
output 
## Elasticsearch单机版
elasticsearch {
          protocol => "http"
          workers => 5
          host => "127.0.0.1"
          flush_size => 10000
          idle_flush_time => 10
          #index => "error-%{+YYYY.MM.dd}"    #可以自定义索引名称
}

## Elasticsearch集群版
     elasticsearch {
          host => "10.0.0.181"
          cluster => "biglog"
          flush_size => 30000
          workers => 3
          index => "biglog-%{+YYYY.MM.dd}"
          }
     }

##自定义template
elasticsearch {
          bind_host => "10.0.0.1"
          protocol => "http"
          workers => 3
          host => "10.0.0.2"
          flush_size => 10000
          idle_flush_time => 10
          index => "netflow-%{+YYYY.MM.dd.HH}"
          template => "/etc/logstash/netflow.json"
          template_name => "netflow"
          manage_template => true
          template_overwrite => true
}

## 输出到文件
file {
          path => "/path/to/file"
          message_format => "%{message}"
}

## 邮件告警
if "DOWN state" in [description] and "down_exclude" not in [tags] {
          email {
                    body => "交换机：%{device}，详细日志：%{message}"
                    #htmlbody => "<h2>%{matchName}</h2><br/><br/><h3>Full Event</h3><br/><br/><div align='center'>%{message}</div>"
                    from => "biglog.alert@biglog.org"
                    subject => "监测到交换机端口断开"
                    to => "anch-noc@anchnet.com, servicedesk@anchnet.com"
                    via => "smtp"
          }
}

##http接口
http {
          url => "http://we7.plusman.cn/api/log.php"
          http_method => "post"
          content_type => "application/json"
          format => "json"
          message => "{'target':{'IPAddress':'"%{FOOIP}"},'commandName':'Test'}"
}

## Redis输出通过Awesant
redis {
          type syslog
          key biglog
          host 10.240.20.13
          port 6379
          database 0
}

#输出zeromq  
zeromq {
          address => ["tcp://0.0.0.0:2112"]
          mode => "server"
          topology => "pushpull"
          tags => ["geoip"]
}
